{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras import backend as k\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 3 classes.\n",
      "Found 500 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "currentPath= os.getcwd()\n",
    "train_dir = os.path.join(currentPath, 'challenge2/train/')\n",
    "validation_dir = os.path.join(currentPath, 'challenge2/val/')\n",
    "\n",
    "image_size=224\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      horizontal_flip=True,shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "      fill_mode='nearest',preprocessing_function = preprocess_input)\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=train_batchsize,\n",
    "        shuffle=True,)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=val_batchsize,\n",
    "        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "0 False\n",
      "1 block1_conv1\n",
      "1 False\n",
      "2 block1_conv2\n",
      "2 False\n",
      "3 block1_pool\n",
      "3 False\n",
      "4 block2_conv1\n",
      "4 False\n",
      "5 block2_conv2\n",
      "5 False\n",
      "6 block2_pool\n",
      "6 False\n",
      "7 block3_conv1\n",
      "7 False\n",
      "8 block3_conv2\n",
      "8 False\n",
      "9 block3_conv3\n",
      "9 False\n",
      "10 block3_pool\n",
      "10 False\n",
      "11 block4_conv1\n",
      "11 False\n",
      "12 block4_conv2\n",
      "12 False\n",
      "13 block4_conv3\n",
      "13 False\n",
      "14 block4_pool\n",
      "14 False\n",
      "15 block5_conv1\n",
      "15 False\n",
      "16 block5_conv2\n",
      "16 False\n",
      "17 block5_conv3\n",
      "17 True\n",
      "18 block5_pool\n",
      "18 True\n",
      "19 global_average_pooling2d_1\n",
      "19 True\n",
      "20 dense_1\n",
      "20 True\n",
      "21 batch_normalization_1\n",
      "21 True\n",
      "22 dropout_1\n",
      "22 True\n",
      "23 dense_2\n",
      "23 True\n",
      "24 batch_normalization_2\n",
      "24 True\n",
      "25 dropout_2\n",
      "25 True\n",
      "26 concatenate_1\n",
      "26 True\n",
      "27 dense_3\n",
      "27 True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           8224        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32)           128         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 544)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            1635        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,857,027\n",
      "Trainable params: 2,501,571\n",
      "Non-trainable params: 12,355,456\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 68s 547ms/step - loss: 1.4683 - acc: 0.4750 - val_loss: 1.2516 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25165, saving model to outputschallenge2/model-001.h5\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 1.1034 - acc: 0.5505 - val_loss: 1.0391 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25165 to 1.03906, saving model to outputschallenge2/model-002.h5\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.9388 - acc: 0.5900 - val_loss: 0.9469 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03906 to 0.94692, saving model to outputschallenge2/model-003.h5\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.8490 - acc: 0.6360 - val_loss: 0.9021 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.94692 to 0.90208, saving model to outputschallenge2/model-004.h5\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 0.7686 - acc: 0.6675 - val_loss: 0.8550 - val_acc: 0.6580\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90208 to 0.85503, saving model to outputschallenge2/model-005.h5\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.7313 - acc: 0.6845 - val_loss: 0.8636 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.85503\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.6574 - acc: 0.7225 - val_loss: 0.7892 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85503 to 0.78923, saving model to outputschallenge2/model-007.h5\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.6239 - acc: 0.7410 - val_loss: 0.7596 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.78923 to 0.75961, saving model to outputschallenge2/model-008.h5\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.5993 - acc: 0.7385 - val_loss: 0.7604 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.75961\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.5763 - acc: 0.7445 - val_loss: 0.7634 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.75961\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.5602 - acc: 0.7575 - val_loss: 0.7493 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.75961 to 0.74934, saving model to outputschallenge2/model-011.h5\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.5175 - acc: 0.7780 - val_loss: 0.7589 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.74934\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.5204 - acc: 0.7755 - val_loss: 0.7177 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.74934 to 0.71773, saving model to outputschallenge2/model-013.h5\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4902 - acc: 0.7970 - val_loss: 0.7121 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.71773 to 0.71210, saving model to outputschallenge2/model-014.h5\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4723 - acc: 0.8050 - val_loss: 0.6870 - val_acc: 0.7280\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.71210 to 0.68699, saving model to outputschallenge2/model-015.h5\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4663 - acc: 0.8000 - val_loss: 0.6809 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.68699 to 0.68089, saving model to outputschallenge2/model-016.h5\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4308 - acc: 0.8105 - val_loss: 0.6672 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.68089 to 0.66716, saving model to outputschallenge2/model-017.h5\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.4386 - acc: 0.8195 - val_loss: 0.6485 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.66716 to 0.64851, saving model to outputschallenge2/model-018.h5\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4235 - acc: 0.8260 - val_loss: 0.6851 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.64851\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.4203 - acc: 0.8310 - val_loss: 0.7205 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.64851\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 0.4033 - acc: 0.8315 - val_loss: 0.6522 - val_acc: 0.7540\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.64851\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 0.3846 - acc: 0.8380 - val_loss: 0.6594 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.64851\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.3584 - acc: 0.8515 - val_loss: 0.6413 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.64851 to 0.64129, saving model to outputschallenge2/model-023.h5\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 34s 276ms/step - loss: 0.3689 - acc: 0.8525 - val_loss: 0.7262 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.64129\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 33s 268ms/step - loss: 0.3570 - acc: 0.8545 - val_loss: 0.6915 - val_acc: 0.7420\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.64129\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 33s 265ms/step - loss: 0.3585 - acc: 0.8535 - val_loss: 0.6878 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.64129\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 0.3503 - acc: 0.8550 - val_loss: 0.6453 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.64129\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.3276 - acc: 0.8670 - val_loss: 0.6549 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.64129\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 0.3212 - acc: 0.8785 - val_loss: 0.6370 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.64129 to 0.63696, saving model to outputschallenge2/model-029.h5\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 32s 257ms/step - loss: 0.3259 - acc: 0.8605 - val_loss: 0.6421 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.63696\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.3141 - acc: 0.8645 - val_loss: 0.6648 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.63696\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.3043 - acc: 0.8755 - val_loss: 0.6562 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.63696\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 0.2921 - acc: 0.8865 - val_loss: 0.6699 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.63696\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.2920 - acc: 0.8850 - val_loss: 0.6853 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.63696\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2786 - acc: 0.8905 - val_loss: 0.6781 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63696\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2840 - acc: 0.8850 - val_loss: 0.6360 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.63696 to 0.63598, saving model to outputschallenge2/model-036.h5\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2729 - acc: 0.8945 - val_loss: 0.6363 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63598\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.2717 - acc: 0.8905 - val_loss: 0.6263 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.63598 to 0.62632, saving model to outputschallenge2/model-038.h5\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2732 - acc: 0.8995 - val_loss: 0.6483 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.62632\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.2578 - acc: 0.9065 - val_loss: 0.6132 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.62632 to 0.61322, saving model to outputschallenge2/model-040.h5\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2516 - acc: 0.9130 - val_loss: 0.6126 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.61322 to 0.61255, saving model to outputschallenge2/model-041.h5\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.2521 - acc: 0.9025 - val_loss: 0.6709 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.61255\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 33s 267ms/step - loss: 0.2347 - acc: 0.9160 - val_loss: 0.6442 - val_acc: 0.7780\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.61255\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.2402 - acc: 0.9075 - val_loss: 0.6577 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.61255\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.2480 - acc: 0.9040 - val_loss: 0.6348 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.61255\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 33s 262ms/step - loss: 0.2250 - acc: 0.9170 - val_loss: 0.6523 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.61255\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 0.2092 - acc: 0.9250 - val_loss: 0.6504 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.61255\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.2198 - acc: 0.9185 - val_loss: 0.6840 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.61255\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.2181 - acc: 0.9190 - val_loss: 0.6823 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.61255\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 0.2289 - acc: 0.9170 - val_loss: 0.7055 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.61255\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 0.2034 - acc: 0.9270 - val_loss: 0.6154 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.61255\n",
      "Epoch 52/200\n",
      " 26/125 [=====>........................] - ETA: 15s - loss: 0.1841 - acc: 0.9399"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f5b3e646aa72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m       verbose=1, callbacks=callbacks_list,shuffle=True)\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda\\envs\\keraspy3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import callbacks\n",
    "reduceLearningRate  = 0.5\n",
    "\n",
    "# base_model = VGG16(weights='imagenet', include_top=False,input_shape=(image_size, image_size, 3))\n",
    "# x = base_model.output\n",
    "# Pool1 = GlobalAveragePooling2D()(x)\n",
    "# Dense1 = Dense(256, activation='relu')(Pool1)\n",
    "# BN1=BatchNormalization()(Dense1)\n",
    "# Dropout1=Dropout(0.5)(BN1)\n",
    "# Dense2 = Dense(32, activation='relu')(Dropout1)\n",
    "# BN2=BatchNormalization()(Dense2)\n",
    "# Dropout2=Dropout(0.5)(BN2)\n",
    "# concat1 = concatenate([Pool1, Dropout2], axis=-1)\n",
    "# predictions = Dense(3, activation='softmax')(Dropout1)\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False,input_shape=(image_size, image_size, 3))\n",
    "x = base_model.output\n",
    "Pool1 = GlobalAveragePooling2D()(x)\n",
    "Dense1 = Dense(256, activation='relu')(Pool1)\n",
    "BN1=BatchNormalization()(Dense1)\n",
    "Dropout1=Dropout(0.5)(BN1)\n",
    "Dense2 = Dense(32, activation='relu')(Dropout1)\n",
    "BN2=BatchNormalization()(Dense2)\n",
    "Dropout2=Dropout(0.5)(BN2)\n",
    "concat1 = concatenate([Pool1, Dropout2], axis=-1)\n",
    "predictions = Dense(3, activation='softmax')(concat1)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[0:17]:\n",
    "     layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)\n",
    "    print (i, layer.trainable)\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "if 'outputschallenge2' not in os.listdir(os.curdir):\n",
    "    os.mkdir('outputschallenge2')\n",
    "\n",
    "\n",
    "log_filename = 'outputschallenge2/' + 'SLC' +'_results.csv'\n",
    "\n",
    "csv_log = callbacks.CSVLogger(log_filename, separator=',', append=True)\n",
    "\n",
    "checkpoint_filepath = 'outputschallenge2/' + 'model-{epoch:03d}.h5'\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_log, checkpoint]\n",
    "callbacks_list.append(ReduceLROnPlateau(factor=reduceLearningRate, patience=20,\n",
    "                                           verbose=True))\n",
    "callbacks_list.append(EarlyStopping(verbose=True, patience=20))\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=200,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1, callbacks=callbacks_list,shuffle=True)\n",
    "\n",
    "\n",
    "model_name = 'outputschallenge2/' + 'SLC' + '_model_last'\n",
    "model.save(model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prediction from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n",
      "500/500 [==============================] - 38s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "currentPath= os.getcwd()\n",
    "test_dir = os.path.join(currentPath, 'datavalchallenge2')\n",
    "image_size=224\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "test_batchsize = 16\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"datavalchallenge2\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator.reset()\n",
    "modelfinal = load_model('outputschallenge2/model-037.h5')\n",
    "\n",
    "pred=modelfinal.predict_generator(test_generator,verbose=1,steps=len(test_generator))\n",
    "\n",
    "#modelfinal.predict(test_generator, batch_size=test_batchsize, verbose=1, steps=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "submissionchal2=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"submissionchal2.csv\", submissionchal2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0 = submissionchal2[0:100]\n",
    "class0pred=class0==0\n",
    "np.sum(class0pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1 = submissionchal2[100:300]\n",
    "class1pred=class1==1\n",
    "np.sum(class1pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2 = submissionchal2[300:500]\n",
    "class2pred=class2==2\n",
    "np.sum(class2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
