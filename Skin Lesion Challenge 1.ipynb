{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras import backend as k\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Challenge 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Train and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 2 classes.\n",
      "Found 1200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "currentPath= os.getcwd()\n",
    "train_dir = os.path.join(currentPath, 'data/train/')\n",
    "validation_dir = os.path.join(currentPath, 'data/val/')\n",
    "image_size=224\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      horizontal_flip=True,shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "      fill_mode='nearest',preprocessing_function = preprocess_input)\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=train_batchsize,\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=val_batchsize,\n",
    "        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "0 False\n",
      "1 block1_conv1\n",
      "1 False\n",
      "2 block1_conv2\n",
      "2 False\n",
      "3 block1_pool\n",
      "3 False\n",
      "4 block2_conv1\n",
      "4 False\n",
      "5 block2_conv2\n",
      "5 False\n",
      "6 block2_pool\n",
      "6 False\n",
      "7 block3_conv1\n",
      "7 False\n",
      "8 block3_conv2\n",
      "8 False\n",
      "9 block3_conv3\n",
      "9 False\n",
      "10 block3_pool\n",
      "10 False\n",
      "11 block4_conv1\n",
      "11 False\n",
      "12 block4_conv2\n",
      "12 False\n",
      "13 block4_conv3\n",
      "13 False\n",
      "14 block4_pool\n",
      "14 False\n",
      "15 block5_conv1\n",
      "15 False\n",
      "16 block5_conv2\n",
      "16 False\n",
      "17 block5_conv3\n",
      "17 True\n",
      "18 block5_pool\n",
      "18 True\n",
      "19 global_average_pooling2d_1\n",
      "19 True\n",
      "20 dense_1\n",
      "20 True\n",
      "21 batch_normalization_1\n",
      "21 True\n",
      "22 dropout_1\n",
      "22 True\n",
      "23 dense_2\n",
      "23 True\n",
      "24 batch_normalization_2\n",
      "24 True\n",
      "25 dropout_2\n",
      "25 True\n",
      "26 concatenate_1\n",
      "26 True\n",
      "27 dense_3\n",
      "27 True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           8224        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32)           128         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 544)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            1090        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,856,482\n",
      "Trainable params: 2,501,026\n",
      "Non-trainable params: 12,355,456\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 165s 549ms/step - loss: 0.7389 - acc: 0.7087 - val_loss: 0.5538 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55377, saving model to outputschallenge1/model-001.h5\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.5155 - acc: 0.7800 - val_loss: 0.4889 - val_acc: 0.7967\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55377 to 0.48889, saving model to outputschallenge1/model-002.h5\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.4615 - acc: 0.7962 - val_loss: 0.4534 - val_acc: 0.8058\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48889 to 0.45345, saving model to outputschallenge1/model-003.h5\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.4186 - acc: 0.8204 - val_loss: 0.4213 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45345 to 0.42130, saving model to outputschallenge1/model-004.h5\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.3938 - acc: 0.8271 - val_loss: 0.4416 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42130\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.3736 - acc: 0.8390 - val_loss: 0.3983 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42130 to 0.39833, saving model to outputschallenge1/model-006.h5\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 80s 266ms/step - loss: 0.3570 - acc: 0.8494 - val_loss: 0.3817 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39833 to 0.38168, saving model to outputschallenge1/model-007.h5\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.3410 - acc: 0.8490 - val_loss: 0.4028 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38168\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.3275 - acc: 0.8558 - val_loss: 0.3666 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38168 to 0.36660, saving model to outputschallenge1/model-009.h5\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 82s 275ms/step - loss: 0.3168 - acc: 0.8621 - val_loss: 0.3598 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36660 to 0.35978, saving model to outputschallenge1/model-010.h5\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 82s 272ms/step - loss: 0.2988 - acc: 0.8721 - val_loss: 0.3682 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35978\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.2859 - acc: 0.8781 - val_loss: 0.3610 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35978\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.2825 - acc: 0.8810 - val_loss: 0.3504 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35978 to 0.35045, saving model to outputschallenge1/model-013.h5\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 82s 275ms/step - loss: 0.2688 - acc: 0.8852 - val_loss: 0.3452 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35045 to 0.34515, saving model to outputschallenge1/model-014.h5\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.2725 - acc: 0.8848 - val_loss: 0.3505 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34515\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.2638 - acc: 0.8867 - val_loss: 0.3387 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.34515 to 0.33872, saving model to outputschallenge1/model-016.h5\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.2520 - acc: 0.8910 - val_loss: 0.3508 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33872\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 81s 268ms/step - loss: 0.2449 - acc: 0.8981 - val_loss: 0.3488 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33872\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.2348 - acc: 0.8935 - val_loss: 0.3423 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33872\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.2348 - acc: 0.8958 - val_loss: 0.3434 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33872\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.2283 - acc: 0.9033 - val_loss: 0.3316 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33872 to 0.33158, saving model to outputschallenge1/model-021.h5\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.2238 - acc: 0.9100 - val_loss: 0.3443 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33158\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.2166 - acc: 0.9110 - val_loss: 0.3272 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33158 to 0.32716, saving model to outputschallenge1/model-023.h5\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.2044 - acc: 0.9144 - val_loss: 0.3374 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32716\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.2070 - acc: 0.9135 - val_loss: 0.3455 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32716\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1924 - acc: 0.9204 - val_loss: 0.3485 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32716\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 84s 279ms/step - loss: 0.1989 - acc: 0.9154 - val_loss: 0.3218 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.32716 to 0.32180, saving model to outputschallenge1/model-027.h5\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1919 - acc: 0.9225 - val_loss: 0.3242 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32180\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1956 - acc: 0.9225 - val_loss: 0.3393 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32180\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1891 - acc: 0.9210 - val_loss: 0.3233 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32180\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 82s 274ms/step - loss: 0.1815 - acc: 0.9267 - val_loss: 0.3174 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.32180 to 0.31742, saving model to outputschallenge1/model-031.h5\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.1727 - acc: 0.9323 - val_loss: 0.3335 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.31742\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 82s 272ms/step - loss: 0.1670 - acc: 0.9335 - val_loss: 0.3334 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.31742\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 82s 273ms/step - loss: 0.1720 - acc: 0.9296 - val_loss: 0.3223 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31742\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.1637 - acc: 0.9352 - val_loss: 0.3412 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31742\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1641 - acc: 0.9375 - val_loss: 0.3268 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31742\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1581 - acc: 0.9390 - val_loss: 0.3296 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31742\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1600 - acc: 0.9346 - val_loss: 0.3353 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31742\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1523 - acc: 0.9435 - val_loss: 0.3188 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31742\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1502 - acc: 0.9448 - val_loss: 0.3242 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.31742\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1436 - acc: 0.9465 - val_loss: 0.3216 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.31742\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1378 - acc: 0.9513 - val_loss: 0.3184 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.31742\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1382 - acc: 0.9469 - val_loss: 0.3249 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.31742\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1376 - acc: 0.9473 - val_loss: 0.3169 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.31742 to 0.31689, saving model to outputschallenge1/model-044.h5\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 81s 268ms/step - loss: 0.1432 - acc: 0.9435 - val_loss: 0.3400 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.31689\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1338 - acc: 0.9490 - val_loss: 0.3127 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.31689 to 0.31268, saving model to outputschallenge1/model-046.h5\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1303 - acc: 0.9510 - val_loss: 0.3182 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.31268\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1245 - acc: 0.9556 - val_loss: 0.3199 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.31268\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1273 - acc: 0.9527 - val_loss: 0.3162 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.31268\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1241 - acc: 0.9554 - val_loss: 0.3224 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.31268\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 80s 266ms/step - loss: 0.1192 - acc: 0.9581 - val_loss: 0.3417 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.31268\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1188 - acc: 0.9590 - val_loss: 0.3446 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.31268\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 82s 274ms/step - loss: 0.1197 - acc: 0.9565 - val_loss: 0.3248 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.31268\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.1134 - acc: 0.9575 - val_loss: 0.3209 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.31268\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.1050 - acc: 0.9644 - val_loss: 0.3177 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.31268\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 82s 272ms/step - loss: 0.1066 - acc: 0.9637 - val_loss: 0.3219 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.31268\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.3195 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.31268\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.1114 - acc: 0.9600 - val_loss: 0.3277 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.31268\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1105 - acc: 0.9625 - val_loss: 0.3349 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.31268\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.1033 - acc: 0.9650 - val_loss: 0.3343 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.31268\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 80s 268ms/step - loss: 0.1042 - acc: 0.9637 - val_loss: 0.3323 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.31268\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0991 - acc: 0.9673 - val_loss: 0.3106 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.31268 to 0.31060, saving model to outputschallenge1/model-062.h5\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 79s 265ms/step - loss: 0.1028 - acc: 0.9648 - val_loss: 0.3440 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.31060\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.1016 - acc: 0.9667 - val_loss: 0.3192 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.31060\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 81s 269ms/step - loss: 0.0949 - acc: 0.9688 - val_loss: 0.3273 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.31060\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.0939 - acc: 0.9673 - val_loss: 0.3215 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.31060\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 83s 277ms/step - loss: 0.0938 - acc: 0.9681 - val_loss: 0.3172 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.31060\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 80s 267ms/step - loss: 0.0873 - acc: 0.9725 - val_loss: 0.3259 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.31060\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0866 - acc: 0.9719 - val_loss: 0.3178 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.31060\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0909 - acc: 0.9704 - val_loss: 0.3162 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.31060\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.0866 - acc: 0.9708 - val_loss: 0.3136 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.31060\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.0864 - acc: 0.9715 - val_loss: 0.3207 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.31060\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 82s 272ms/step - loss: 0.0867 - acc: 0.9717 - val_loss: 0.3428 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.31060\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0838 - acc: 0.9735 - val_loss: 0.3527 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.31060\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 83s 276ms/step - loss: 0.0843 - acc: 0.9704 - val_loss: 0.3226 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.31060\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 82s 273ms/step - loss: 0.0784 - acc: 0.9744 - val_loss: 0.3360 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.31060\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.0783 - acc: 0.9746 - val_loss: 0.3240 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.31060\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0798 - acc: 0.9744 - val_loss: 0.3382 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.31060\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 81s 270ms/step - loss: 0.0805 - acc: 0.9752 - val_loss: 0.3253 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.31060\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 81s 271ms/step - loss: 0.0742 - acc: 0.9752 - val_loss: 0.3266 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.31060\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 80s 266ms/step - loss: 0.0740 - acc: 0.9754 - val_loss: 0.3285 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.31060\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 80s 266ms/step - loss: 0.0673 - acc: 0.9810 - val_loss: 0.3191 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.31060\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 00082: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import callbacks\n",
    "reduceLearningRate  = 0.5\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False,input_shape=(image_size, image_size, 3))\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "Pool1 = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "#x=Flatten()(x)\n",
    "Dense1 = Dense(256, activation='relu')(Pool1)\n",
    "BN1=BatchNormalization()(Dense1)\n",
    "Dropout1=Dropout(0.5)(BN1)\n",
    "Dense2 = Dense(32, activation='relu')(Dropout1)\n",
    "BN2=BatchNormalization()(Dense2)\n",
    "Dropout2=Dropout(0.5)(BN2)\n",
    "concat1 = concatenate([Pool1, Dropout2], axis=-1)\n",
    "\n",
    "predictions = Dense(2, activation='softmax')(concat1)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[0:17]:\n",
    "     layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)\n",
    "    print (i, layer.trainable)\n",
    "\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "if 'outputschallenge1' not in os.listdir(os.curdir):\n",
    "    os.mkdir('outputschallenge1')\n",
    "\n",
    "\n",
    "log_filename = 'outputschallenge1/' + 'SLC' +'_results.csv'\n",
    "\n",
    "csv_log = callbacks.CSVLogger(log_filename, separator=',', append=True)\n",
    "\n",
    "checkpoint_filepath = 'outputschallenge1/' + 'model-{epoch:03d}.h5'\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_log, checkpoint]\n",
    "callbacks_list.append(ReduceLROnPlateau(factor=reduceLearningRate, patience=20,\n",
    "                                           verbose=True))\n",
    "callbacks_list.append(EarlyStopping(verbose=True, patience=20))\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1, callbacks=callbacks_list,shuffle=True)\n",
    "\n",
    "\n",
    "model_name = 'outputschallenge1/' + 'SLC' + '_model_last'\n",
    "model.save(model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get the final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('outputschallenge1/model-062.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1015 images belonging to 1 classes.\n",
      "0\n",
      "1015/1015 [==============================] - 15s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "currentPath= os.getcwd()\n",
    "test_dir = os.path.join(currentPath, 'testChallenge1/')\n",
    "image_size=224\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "test_batchsize = 16\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"testChallenge1/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42)\n",
    "\n",
    "test_generator.reset()\n",
    "print (max(test_generator.classes))\n",
    "#modelfinal = load_model('outputschallenge1/model-062.h5')\n",
    "\n",
    "pred=model.predict_generator(test_generator,verbose=1,steps=len(test_generator))\n",
    "\n",
    "#modelfinal.predict(test_generator, batch_size=test_batchsize, verbose=1, steps=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
